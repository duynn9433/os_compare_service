import requests
import json
import time
from tqdm import tqdm  # Cho hiá»ƒn thá»‹ tiáº¿n trÃ¬nh

ES_HOST = "http://localhost:9200"
INDEX_NAME = "test-index"
DATA_FILE = "data.jsonl"
BULK_SIZE = 500  # Sá»‘ lÆ°á»£ng documents má»—i láº§n ghi bulk

HEADERS = {"Content-Type": "application/x-ndjson"}

# Láº¥y tá»•ng sá»‘ document trong index
def get_doc_count():
    url = f"{ES_HOST}/{INDEX_NAME}/_count"
    response = requests.get(url)
    if response.status_code == 200:
        return response.json().get("count", 0)
    return -1

# Bulk ghi dá»¯ liá»‡u
def bulk_insert(docs):
    bulk_payload = ""
    for doc in docs:
        meta = {"index": {"_index": INDEX_NAME}}
        bulk_payload += json.dumps(meta) + "\n" + json.dumps(doc) + "\n"
    response = requests.post(f"{ES_HOST}/_bulk", headers=HEADERS, data=bulk_payload)
    return response

# Ghi toÃ n bá»™ file dá»¯ liá»‡u vÃ o Elasticsearch
def ingest_documents(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        batch = []
        total = 0
        errors = 0
        start_time = time.time()

        for line in tqdm(f, desc="Processing JSONL"):
            doc = json.loads(line)
            batch.append(doc)
            if len(batch) >= BULK_SIZE:
                resp = bulk_insert(batch)
                total += len(batch)
                if resp.status_code != 200 or resp.json().get("errors", False):
                    errors += 1
                batch = []

        # Insert pháº§n cÃ²n láº¡i
        if batch:
            resp = bulk_insert(batch)
            total += len(batch)
            if resp.status_code != 200 or resp.json().get("errors", False):
                errors += 1

        end_time = time.time()
        elapsed = end_time - start_time
        print("\n=== ğŸ“Š Ingestion Report ===")
        print(f"ğŸ•’ Time taken     : {elapsed:.2f} seconds")
        print(f"ğŸ“„ Total inserted: {total} documents")
        print(f"âš ï¸  Bulk errors  : {errors} chunks")
        print(f"ğŸš€ Insert speed  : {total / elapsed:.2f} docs/sec")
        return elapsed, total, errors

if __name__ == "__main__":
    print("ğŸ” Counting documents before insert...")
    count_before = get_doc_count()
    print(f"ğŸ“Œ Documents before: {count_before}")

    print("ğŸš€ Inserting documents from file...")
    duration, inserted, error_batches = ingest_documents(DATA_FILE)

    print("ğŸ” Counting documents after insert...")
    count_after = get_doc_count()
    print(f"âœ… Documents after: {count_after}")
    print(f"ğŸ“Š Documents added: {count_after - count_before}")